{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "020b4f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Importing libraries and module\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from pytube import YouTube\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from youtube_module import get_channel_details\n",
    "from pytube import YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecd31ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE_URL = 'https://www.naukri.com/mnjuser/homepage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56f3dee8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'link' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m browser \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome(service\u001b[38;5;241m=\u001b[39mservice, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[0;32m      4\u001b[0m browser\u001b[38;5;241m.\u001b[39mget(BASE_URL)\n\u001b[1;32m----> 5\u001b[0m browser\u001b[38;5;241m.\u001b[39mget(\u001b[43mlink\u001b[49m)\n\u001b[0;32m      6\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      7\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(browser\u001b[38;5;241m.\u001b[39mpage_source, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'link' is not defined"
     ]
    }
   ],
   "source": [
    "# service = Service(executable_path= 'chromedriver.exe')\n",
    "# options = webdriver.ChromeOptions()\n",
    "# browser = webdriver.Chrome(service=service, options=options)\n",
    "# browser.get(BASE_URL)\n",
    "# browser.get(link)\n",
    "# time.sleep(1)\n",
    "# soup = BeautifulSoup(browser.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a3a1d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Title: Data Science Intern\n",
      "Job Description: Job Overview:\n",
      "Node App is a Techstars and a Silicon Valley-backed startup on a mission to democratize the creator economy. We empower brands and content creators to forge stronger connections. Our platform facilitates custom photo and video production for consumer brands by connecting them with influencers and content creators. We've supported over 2,000 North American brands in creating streamlined, data-driven UGC campaigns.\n",
      "Our product team is seeking a talented data scientist to enhance customer experiences and optimize data processing through innovative computer vision and machine learning techniques. You'll collaborate directly with the co-founders and product team to develop scalable models for large agencies and major brands.\n",
      "This role offers unparalleled freedom and flexibility to experiment with cutting-edge tools and methodologies while making an impact in a dynamic startup environment.\n",
      "\n",
      "\n",
      "Job Title: Data Scientist\n",
      "Job Description: Position : Data Scientist\n",
      "Location : Remote\n",
      "Mode : Contract\n",
      "Job Description :\n",
      "· Data scientist with experience building ML models.\n",
      "· Experience with Google Analytics 4, iBQML (Big Query Machine Learning) – essentially running ML commands directly in the BigQuery console.\n",
      "· Domain experience in marketing is highly preferred.\n",
      "Must have skills :\n",
      "· Machine Learning\n",
      "· Google Analytics\n",
      "\n",
      "\n",
      "Job Title: Data Scientist\n",
      "Job Description: Data Science & Search is a central technology team at Clarivate that develops best in class algorithmic services and search platforms for our products to enable differentiated capabilities. We take pride in innovating on behalf of our customers and delivering value to the business. Our scientists and engineers use Machine Learning, NLP, and Information Retrieval to solve problems along the entire Lifecycle of Innovation. From algorithms to classify content, to automating content extraction workflows, extracting and resolving entities, building recommender and decision support systems, predicting risk and outcomes, and enabling unique ways of finding content, these are just a few of the ways our team is fostering productivity of our customers who lead innovation in the world.\n",
      "About You – experience, education, skills, and accomplishments\n",
      "Advanced degree in Computer Science, Statistics, Engineering, Physics, Mathematics, or other quantitative majors, or equivalent work experience.\n",
      "\n",
      "\n",
      "Job Title: Data Scientist\n",
      "Job Description: Data Scientist - INF004602\n",
      "Employment Type: Permanent Full-time\n",
      "Location(s): SK-Rgna-Regina\n",
      "Ministry: 016 Highways\n",
      "Salary Range: $7,049 to $9,165 Monthly\n",
      "Grade: MCP.07.\n",
      "At the Ministry of Highways, we work with our partners to provide a safe, reliable transportation system. The ministry considers its data a valuable asset that allows us to be more transparent, collaborative and citizen-centered through data driven insights and decisions.\n",
      "The Opportunity\n",
      "The Information Management Unit at the Ministry of Highways is seeking a Data Scientist that is highly motived, detail-orientated, innovative and an effective communicator.\n",
      "\n",
      "\n",
      "Error extracting details from https://www.glassdoor.ca/job-listing/data-scientist-machine-learning-ample-insight-inc-JV_IC2281069_KO0,31_KE32,49.htm?jl=1009126057716: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"h1.heading_Heading__BqX5J\"}\n",
      "  (Session info: chrome=126.0.6478.182)\n",
      "\n",
      "Error extracting details from https://www.glassdoor.ca/job-listing/data-scientist-instacart-JV_KO0,14_KE15,24.htm?jl=1009005705913: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"h1.heading_Heading__BqX5J\"}\n",
      "  (Session info: chrome=126.0.6478.182)\n",
      "\n",
      "Error extracting details from https://www.glassdoor.ca/job-listing/data-scientist-knowtions-research-inc-oa-lydia-ai-JV_IC2281069_KO0,14_KE15,49.htm?jl=1009358040808: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"h1.heading_Heading__BqX5J\"}\n",
      "  (Session info: chrome=126.0.6478.182)\n",
      "\n",
      "Error extracting details from https://www.glassdoor.ca/job-listing/data-scientist-ii-td-bank-JV_IC2281069_KO0,17_KE18,25.htm?jl=1009326650831: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=126.0.6478.182)\n",
      "\n",
      "Error extracting details from https://www.glassdoor.ca/job-listing/data-scientist-lydia-ai-JV_IC2281069_KO0,14_KE15,23.htm?jl=1009373151093: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=126.0.6478.182)\n",
      "\n",
      "Error extracting details from https://www.glassdoor.ca/job-listing/healthcare-data-scientist-nlb-technology-services-JV_KO0,25_KE26,49.htm?jl=1009361502094: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=126.0.6478.182)\n",
      "\n",
      "Error extracting details from https://www.glassdoor.ca/job-listing/senior-data-scientist-pembina-pipeline-corporation-JV_IC2275123_KO0,21_KE22,50.htm?jl=1009356944702: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=126.0.6478.182)\n",
      "\n",
      "Error extracting details from https://www.glassdoor.ca/job-listing/data-scientist-dropbox-JV_KO0,14_KE15,22.htm?jl=1009322301708: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=126.0.6478.182)\n",
      "\n",
      "Error extracting details from https://www.glassdoor.ca/job-listing/jr-data-scientist-tundra-oil-gas-limited-JV_IC2275123_KO0,17_KE18,40.htm?jl=1009358585106: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=126.0.6478.182)\n",
      "\n",
      "Error extracting details from https://www.glassdoor.ca/job-listing/data-scientist-with-machine-learning-tekshapers-software-solutions-pvt-ltd-JV_KO0,36_KE37,74.htm?jl=1009371248281: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=126.0.6478.182)\n",
      "\n",
      "Error extracting details from https://www.glassdoor.ca/job-listing/data-scientist-trust-safety-textnow-JV_KO0,27_KE28,35.htm?jl=1009354025967: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=126.0.6478.182)\n",
      "\n",
      "Error extracting details from https://www.glassdoor.ca/job-listing/data-scientist-ample-insight-inc-JV_IC2281069_KO0,14_KE15,32.htm?jl=1008986324898: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=126.0.6478.182)\n",
      "\n",
      "Error extracting details from https://www.glassdoor.ca/job-listing/data-scientist-bondr-JV_IC2281069_KO0,14_KE15,20.htm?jl=1009010323292: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=126.0.6478.182)\n",
      "\n",
      "Error extracting details from https://www.glassdoor.ca/job-listing/data-scientist-johnson-johnson-innovative-medicine-commercial-data-sciences-johnson-johnson-JV_IC2281069_KO0,75_KE76,91.htm?jl=1009364159012: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=126.0.6478.182)\n",
      "\n",
      "Error extracting details from https://www.glassdoor.ca/job-listing/intern-associate-business-data-scientist-kinaxis-inc-JV_KO0,40_KE41,52.htm?jl=1009373602498: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=126.0.6478.182)\n",
      "\n",
      "Error extracting details from https://www.glassdoor.ca/job-listing/data-scientist-the-home-depot-canada-JV_IC2281069_KO0,14_KE15,36.htm?jl=1009371367536: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=126.0.6478.182)\n",
      "\n",
      "Error extracting details from https://www.glassdoor.ca/job-listing/data-scientist-atlantis-it-group-JV_IC2281069_KO0,14_KE15,32.htm?jl=1008947216691: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=126.0.6478.182)\n",
      "\n",
      "Error extracting details from https://www.glassdoor.ca/job-listing/hockey-data-analyst-analyste-de-données-de-hockey-sportlogiq-JV_KO0,49_KE50,60.htm?jl=1009376111011: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=126.0.6478.182)\n",
      "\n",
      "Error extracting details from https://www.glassdoor.ca/job-listing/data-scientist-kirmac-JV_IC3708260_KO0,14_KE15,21.htm?jl=1009342771055: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=126.0.6478.182)\n",
      "\n",
      "Error extracting details from https://www.glassdoor.ca/job-listing/deep-learning-applied-scientist-ai-new-college-graduate-2024-nvidia-JV_IC2281069_KO0,60_KE61,67.htm?jl=1009371661093: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=126.0.6478.182)\n",
      "\n",
      "Error extracting details from https://www.glassdoor.ca/job-listing/staff-data-scientist-clearco-JV_KO0,20_KE21,28.htm?jl=1009354109321: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=126.0.6478.182)\n",
      "\n",
      "Error extracting details from https://www.glassdoor.ca/job-listing/associate-data-scientist-allstate-JV_IC2280736_KO0,24_KE25,33.htm?jl=1009358382123: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=126.0.6478.182)\n",
      "\n",
      "Error extracting details from https://www.glassdoor.ca/job-listing/data-scientist-profound-medical-JV_IC2280741_KO0,14_KE15,31.htm?jl=1009373435981: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=126.0.6478.182)\n",
      "\n",
      "Error extracting details from https://www.glassdoor.ca/job-listing/data-scientist-access-pacific-enterprises-ltd-JV_IC2303209_KO0,14_KE15,45.htm?jl=1009373652051: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=126.0.6478.182)\n",
      "\n",
      "Error extracting details from https://www.glassdoor.ca/job-listing/data-scientist-bmo-financial-group-JV_IC2281069_KO0,14_KE15,34.htm?jl=1009371276801: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=126.0.6478.182)\n",
      "\n",
      "Error extracting details from https://www.glassdoor.ca/job-listing/data-scientist-sobeys-JV_IC2290724_KO0,14_KE15,21.htm?jl=1009372581747: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=126.0.6478.182)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Initialize Selenium WebDriver\n",
    "path = 'chromedriver.exe'\n",
    "options = Options()\n",
    "driver = webdriver.Chrome(executable_path=path, options=options)\n",
    "driver.set_window_size(1120, 1000)\n",
    "\n",
    "# URL of the page containing JSON-LD data\n",
    "page_url = 'https://api.scrapingdog.com/scrape?api_key=669facfcaa98341fa8bba0de&url=https://www.glassdoor.ca/Job/canada-data-scientist-jobs-SRCH_IL.0,6_IN3_KO7,21.htm&dynamic=false'  # Replace with the actual URL\n",
    "\n",
    "# Load the webpage using Selenium\n",
    "driver.get(page_url)\n",
    "\n",
    "# Wait for the page to load (you may need to adjust the sleep time or use WebDriverWait)\n",
    "time.sleep(5)\n",
    "\n",
    "# Find the JSON-LD script tag\n",
    "try:\n",
    "    json_ld_script = driver.find_element(By.CSS_SELECTOR, 'script[type=\"application/ld+json\"]').get_attribute('innerHTML')\n",
    "    json_ld_data = json.loads(json_ld_script)\n",
    "\n",
    "    # Extract job URLs from JSON-LD data\n",
    "    job_urls = [item['url'] for item in json_ld_data.get('itemListElement', [])]\n",
    "except Exception as e:\n",
    "    print(f\"Error extracting JSON-LD data: {e}\")\n",
    "    job_urls = []\n",
    "\n",
    "# Iterate through job URLs and extract details\n",
    "for url in job_urls:\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(5)  # Wait for job page to load\n",
    "\n",
    "        # Extract job title\n",
    "        job_title = driver.find_element(By.CSS_SELECTOR, 'h1.heading_Heading__BqX5J').text\n",
    "\n",
    "        # Extract job description\n",
    "        job_description = driver.find_element(By.CSS_SELECTOR, 'div.JobDetails_jobDescription__uW_fK').text\n",
    "\n",
    "        # Print job details\n",
    "        print(f\"Job Title: {job_title}\")\n",
    "        print(f\"Job Description: {job_description}\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting details from {url}: {e}\")\n",
    "\n",
    "# Close the Selenium WebDriver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f1e7e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62c69f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from serpapi import GoogleSearch\n",
    "import os, json\n",
    "\n",
    "params = {\n",
    "\t'api_key': 'axxxxxxx',                           # https://serpapi.com/manage-api-key\n",
    "\t# https://site-analyzer.pro/services-seo/uule/\n",
    "\t'uule': 'w+CAIQICINVW5pdGVkIFN0YXRlcw',\t\t# encoded location (India)\n",
    "\t'q': 'data scientist',              \t\t# search query\n",
    "    'hl': 'en',                         \t\t# language of the search\n",
    "    'gl': 'in',                         \t\t# country of the search\n",
    "\t'engine': 'google_jobs',\t\t\t\t\t# SerpApi search engine\n",
    "\t'start': 0\t\t\t\t\t\t\t\t\t# pagination\n",
    "}\n",
    "\n",
    "google_jobs_results = []\n",
    "\n",
    "while True:\n",
    "    search = GoogleSearch(params)   \t\t\t# where data extraction happens on the SerpApi backend\n",
    "    result_dict = search.get_dict() \t\t\t# JSON -> Python dict\n",
    "\n",
    "    if 'error' in result_dict:\n",
    "        break\n",
    "    \n",
    "    for result in result_dict['jobs_results']:\n",
    "        google_jobs_results.append(result)\n",
    "\n",
    "    params['start'] += 10\n",
    "\n",
    "print(json.dumps(google_jobs_results, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19b809fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_details = []\n",
    "\n",
    "# Iterate through each job data dictionary\n",
    "for job_data in google_jobs_results:\n",
    "    # Extract relevant information\n",
    "    title = job_data['title']\n",
    "    company_name = job_data['company_name']\n",
    "    location = job_data['location']\n",
    "    via = job_data['via']\n",
    "    description = job_data['description']\n",
    "    related_links = \"\\n\".join([f\"[{link['text']}]({link['link']})\" for link in job_data['related_links']])\n",
    "\n",
    "    # Append job details as a dictionary to the list\n",
    "    job_details.append({\n",
    "        'Title': title,\n",
    "        'Company Name': company_name,\n",
    "        'Location': location,\n",
    "        'Via': via,\n",
    "        'Description': description,\n",
    "        'Thumbnail': thumbnail,\n",
    "        'Posted At': posted_at,\n",
    "        'Schedule Type': schedule_type,\n",
    "        'Related Links': related_links\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(job_details)\n",
    "\n",
    "# Display the DataFrame\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9f8fa81-c1d9-4ace-b16f-a48de6490120",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"job_details.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a62c1c5-c11b-4045-a1d6-20efde1f5f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"job_details.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a14336d8-53ce-4201-aa14-411ddb5b1cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"Title\",\"Description\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "276d2fc8-8e85-47cb-aa09-c6623aa9224d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Senior Level Data Scientist**\n",
      "\n",
      "**Responsibilities:**\n",
      "\n",
      "* Lead and manage a team of data scientists in developing and deploying machine learning solutions\n",
      "* Provide expert guidance and mentorship to junior data scientists\n",
      "* Collaborate with business stakeholders to understand data needs and translate them into technical requirements\n",
      "* Design and implement data pipelines, including data cleaning, feature engineering, and model training\n",
      "* Build predictive models that leverage Python and machine learning algorithms to drive business outcomes\n",
      "* Present findings and recommendations to stakeholders effectively and persuasively\n",
      "* Stay abreast of emerging industry trends and advancements in data science\n",
      "\n",
      "**Qualifications:**\n",
      "\n",
      "* PhD or Master's degree in Computer Science, Data Science, or a related field\n",
      "* Minimum of 5 years of experience as a data scientist with a solid foundation in Python and machine learning\n",
      "* Proven expertise in building and deploying predictive models\n",
      "* Excellent data analysis and visualization skills\n",
      "* Strong understanding of statistical methods and concepts\n",
      "* Experience in developing and managing data pipelines\n",
      "* Exceptional communication and presentation abilities\n",
      "* Ability to work independently and as part of a team in a fast-paced environment\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Set up your API key\n",
    "os.environ['GOOGLE_API_KEY'] = \"AIxxxxxxx\"\n",
    "genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
    "\n",
    "# Initialize the generative model\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "def generate_job_description(keywords: list, level: str) -> str:\n",
    "    # Create a prompt for the job description\n",
    "    prompt = f\"\"\"\n",
    "    Given the following keywords: {', '.join(keywords)}, create a job description for a {level} Data Scientist role.\n",
    "\n",
    "    Job Description:\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate content\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "# Example usage\n",
    "keywords = ['experience in Python', 'machine learning', 'data analysis', 'scientist with experience', 'data scientist', 'Python', 'building predictive models', 'Responsibilities include building', 'data', 'include building predictive']\n",
    "job_description = generate_job_description(keywords, 'Senior Level')\n",
    "print(job_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2acce0-49ad-44c3-9806-3438f5dccff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_17168\\3623877943.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_batch['keywords'] = df_batch['Description'].apply(extract_keywords)\n",
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_17168\\3623877943.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_batch['Experience Level'] = df_batch.apply(lambda row: classify_position(row['Title'], row['Description'], model), axis=1)\n",
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_17168\\3623877943.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_batch['keywords'] = df_batch['Description'].apply(extract_keywords)\n",
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_17168\\3623877943.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_batch['Experience Level'] = df_batch.apply(lambda row: classify_position(row['Title'], row['Description'], model), axis=1)\n",
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_17168\\3623877943.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_batch['keywords'] = df_batch['Description'].apply(extract_keywords)\n",
      "C:\\Users\\Ayush\\AppData\\Local\\Temp\\ipykernel_17168\\3623877943.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_batch['Experience Level'] = df_batch.apply(lambda row: classify_position(row['Title'], row['Description'], model), axis=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "import yake\n",
    "import time\n",
    "\n",
    "# Set your Google API key\n",
    "os.environ['GOOGLE_API_KEY'] = \"AIXXXXXX\"\n",
    "genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
    "\n",
    "# Initialize the generative model for text summarization\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "def extract_keywords(text: str, max_keywords: int = 10):\n",
    "    kw_extractor = yake.KeywordExtractor()\n",
    "    keywords = kw_extractor.extract_keywords(text)\n",
    "    return [kw[0] for kw in keywords[:max_keywords]]\n",
    "\n",
    "def classify_position(title: str, description: str, model) -> str:\n",
    "    \"\"\"\n",
    "    Classifies the job position based on the title and description using the generative model.\n",
    "    \n",
    "    :param title: Job title\n",
    "    :param description: Job description\n",
    "    :param model: Generative model instance\n",
    "    :return: Experience level classification\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Job Title: {title}\n",
    "    Job Description: {description}\n",
    "    \n",
    "    Based on the job title and description provided, classify the job position as either Entry Level, Mid Level, or Senior Level.\n",
    "    Provide a clear and concise classification.\n",
    "    \n",
    "    Classification:\n",
    "    \"\"\"\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            classification = response.text.strip()\n",
    "            return classification\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}. Waiting before retrying...\")\n",
    "            time.sleep(60)  # Wait for 60 seconds before retrying\n",
    "\n",
    "def process_batch(df_batch: pd.DataFrame, model) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process a batch of job descriptions to classify them.\n",
    "    \n",
    "    :param df_batch: Batch of job descriptions DataFrame\n",
    "    :param model: Generative model instance\n",
    "    :return: DataFrame with classified job positions\n",
    "    \"\"\"\n",
    "    df_batch['keywords'] = df_batch['Description'].apply(extract_keywords)\n",
    "    df_batch['Experience Level'] = df_batch.apply(lambda row: classify_position(row['Title'], row['Description'], model), axis=1)\n",
    "    return df_batch\n",
    "\n",
    "# Read data from Excel file\n",
    "df = pd.read_excel('job_descriptions.xlsx')\n",
    "df_rows_11_to_20 = df.iloc[90:100]\n",
    "df = df_rows_11_to_20.copy()\n",
    "\n",
    "# Ensure DataFrame columns are named appropriately\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# Define batch size and initialize results list\n",
    "batch_size = 1\n",
    "results = []\n",
    "\n",
    "# Process the DataFrame in batches\n",
    "for start_idx in range(0, len(df), batch_size):\n",
    "    end_idx = start_idx + batch_size\n",
    "    batch = df.iloc[start_idx:end_idx]\n",
    "    processed_batch = process_batch(batch, model)\n",
    "    results.append(processed_batch)\n",
    "\n",
    "# Concatenate all batches into a single DataFrame\n",
    "final_df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "print(final_df[['Title', 'Description', 'keywords', 'Experience Level']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02555bc6-ecb7-4d7e-a032-6449f9d18ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.to_excel(\"testing10.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc1c79aa-d1d8-44f8-b48c-9cb7400d9229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "import yake\n",
    "import time\n",
    "\n",
    "# Set your Google API key\n",
    "os.environ['GOOGLE_API_KEY'] = \"AIxxxxxx\"\n",
    "genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
    "\n",
    "# Initialize the generative model for text summarization\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "def rank_keywords(keywords_list):\n",
    "    ranked_keywords = []\n",
    "    for keywords in keywords_list:\n",
    "        prompt = f\"Rank the importance of these keywords for a Data Scientist role: {', '.join(keywords)}\"\n",
    "        try:\n",
    "            response = genai.GenerativeModel('gemini-pro').generate_content(prompt)\n",
    "            if response and response.parts:\n",
    "                ranked_keywords.append((keywords, response.parts[0].text))  # Adjust based on actual response\n",
    "            else:\n",
    "                ranked_keywords.append((keywords, \"No response text available\"))\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating content for keywords {keywords}: {e}\")\n",
    "            ranked_keywords.append((keywords, \"Error\"))\n",
    "    return ranked_keywords\n",
    "df = pd.read_excel(\"testing.xlsx\")\n",
    "df = df[df[\"Experience Level\"]==\"Mid Level\"]\n",
    "df.reset_index(inplace=True)\n",
    "df_rows_11_to_20 = df.iloc[40:50]\n",
    "df = df_rows_11_to_20.copy()\n",
    "# print(df)\n",
    "\n",
    "# print(df)\n",
    "# Rank keywords\n",
    "ranked_keywords = rank_keywords(df['keywords'].tolist())\n",
    "\n",
    "# Sort keywords by ranking and get top 10\n",
    "ranked_keywords.sort(key=lambda x: x[1])  # Adjust sorting based on ranking text\n",
    "top_10_keywords = [kw[0] for kw in ranked_keywords[:5]]\n",
    "data = pd.DataFrame()\n",
    "data[\"topkeywords\"] = top_10_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e6c433f-8495-454d-a7f3-3cd3ab1e0665",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data[\"topkeywords\"] = top_10_keywords\n",
    "data.to_excel(\"mid_top3.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "323f29d3-507d-42be-870c-e0de8945f981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Job Description:\n",
      "**Data Scientist (Entry-Level)**\n",
      "\n",
      "**About the Role**\n",
      "\n",
      "Harnessing the power of data, we are seeking an aspiring Data Scientist to join our team and contribute to the company's data-driven success. This entry-level role is an excellent opportunity for individuals passionate about extracting insights from vast datasets and transforming them into actionable intelligence.\n",
      "\n",
      "**Responsibilities**\n",
      "\n",
      "* Collaborate with cross-functional teams to identify and prioritize data-driven initiatives\n",
      "* Cleanse, prepare, and analyze large and complex datasets using statistical and machine learning techniques\n",
      "* Develop and implement predictive models to forecast future trends and make data-informed recommendations\n",
      "* Utilize visualization tools to present findings in a compelling and understandable manner\n",
      "* Stay abreast of emerging technologies and methodologies in the field of data science\n",
      "\n",
      "**Qualifications**\n",
      "\n",
      "* Strong academic background in Data Science, Statistics, Computer Science, or a related field (Master's degree preferred)\n",
      "* Excellent analytical, problem-solving, and critical thinking skills\n",
      "* Proficiency in data manipulation languages such as Python, R, or SQL\n",
      "* Experience with machine learning libraries (e.g., TensorFlow, scikit-learn)\n",
      "* Familiarity with cloud-based data platforms (e.g., AWS, Azure)\n",
      "* Strong communication and presentation skills\n",
      "\n",
      "**Why Join Us?**\n",
      "\n",
      "* Be part of a team of innovative and passionate individuals\n",
      "* Work on challenging and impactful projects\n",
      "* Receive mentorship from experienced data scientists\n",
      "* Access to cutting-edge data science tools and resources\n",
      "* Competitive salary and benefits package\n",
      "\n",
      "If you are eager to embark on a rewarding career in data science, we encourage you to apply. Your ability to unlock the value of data and drive informed decision-making will be an invaluable asset to our organization.\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import yake\n",
    "import time\n",
    "\n",
    "# Set your Google API key\n",
    "os.environ['GOOGLE_API_KEY'] = \"AIXXXXXXXX\"\n",
    "genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n",
    "\n",
    "df = pd.read_excel(\"entry_level_keywords.xlsx\")\n",
    "# Combine all keywords into a single list and remove duplicates\n",
    "all_keywords = set(keyword for sublist in df['topkeywords'] for keyword in sublist)\n",
    "\n",
    "# Convert to a sorted list (optional)\n",
    "all_keywords_list = sorted(all_keywords)\n",
    "\n",
    "# Define the prompt template\n",
    "query = \"Data Scientist\"\n",
    "level = \"Entry\"\n",
    "prompt_template = \"\"\"\n",
    "Given the following keywords: {keywords}, create a job description for a {query} role at the {level} level.\n",
    "Please follow all of the following rules when summarising:\n",
    "1/ Make sure the content is engaging and informative\n",
    "2/ The content should address the {query} topic thoroughly\n",
    "3/ The content needs to be written in a way that is easy to read and understand\n",
    "4/ The content should include key responsibilities and qualifications\n",
    "5/ Ensure that the content highlights the most important aspects of the role\n",
    "6/ The content needs to be written in a more elaborate way and detailed\n",
    "\"\"\"\n",
    "\n",
    "# Function to generate job description using Gemini Pro Vision\n",
    "def generate_job_description(keywords: list, query: str, level: str) -> str:\n",
    "    prompt = prompt_template.format(keywords=', '.join(keywords), query=query, level=level)\n",
    "    try:\n",
    "        response = genai.GenerativeModel('gemini-pro').generate_content(prompt)\n",
    "        return response.text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \"Error generating job description.\"\n",
    "\n",
    "# Generate job description from combined keywords\n",
    "job_description = generate_job_description(all_keywords_list, query, level)\n",
    "\n",
    "print(\"Generated Job Description:\")\n",
    "print(job_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0f1835-1141-4276-bc05-df82df269f52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
